// Copyright (c) 2013-2015 K Team. All Rights Reserved.
/* BUGS:

Due to now JavaCC handles EOF, EOF cannot terminate a single-line comment

The current method of computing follow sets is wrong, but it emulates
the behavior of the previous system.

*/

/* DISCUSSION ITEMS:

Is one of "priorities" or "priority" depricated/preferred? If so, should the other trigger a warning?

The PriorityBlockExtend class has an "assoc" field. Does this need to be set?  What should it be set to?

inconsistency in whether comments are inside rule and lexical or not

"List" is not a keyword (!)

Why "Keyword [ RL ] : BUBBLE" instead of "Keyword [ RL ] BUBBLE"?

Some way to generalize FUNCTIONID and TupleProd?

Strings in KIL should be enum

Tabs in comments should not be translated to spaces

*/


/***** IDIOMS USED IN THIS FILE *****

PARAMETERS AND RETURN VALUES

There are two styles of writing productions that are used in this
grammar.  The first simply returns the parsed object.  For example,
the 'Bubble' production returns a String.  The second takes a
parameter representing the parent node that the production should add
a child to.  For example, the 'Require' production returns 'void' and
takes a 'List<DefinitionItem>' as parameter.  Once successfully
parsed, 'Require' object is added to this 'List'.

In different cases, one or the other style is easier to use so the
code freely mixes between the two styles.

SOURCE LOCATION INFORMATION

At the start of each production, we call 'startLoc()'.  This function
queries the start location of the next token and returns part of the
String that will be used to represent the location of the current
production.

At the end of each production, we call 'markLoc' before returning.
This function takes as parameter the String returned by 'startLoc' and
the 'ASTNode'.  It then queries the last token consumed for its end
position and adds an 'location' attribute to the 'ASTNode' for the
given start and end locations.  Finally, it returns the 'ASTNode' that
was passed to it.  The reason it returns the 'ASTNode' is as a
convenience so you can write things like the following without having
to save the newly created 'ASTNode' to a variable:

  return markLoc(loc, new NonTerminal(Sort.of(image())));

For single token 'ASTNode' objects, the function 'tokenLoc' computes
both the start and end location from the start and end location of the
last token consumed.  The only parameter that it takes is the
'ASTNode' that this start location is to return.  Like 'markLoc' this
function also returns the given 'ASTNode'.

The final complication is that since a 'Bubble' is parsed by a second
pass in the 'makeStringSentence' method we have to store an offset to
the source locations that is used in the second pass of parsing.
These offsets are stored in 'beginLine', 'beginColumn'.

COMMENTS

Comments are handled by calling the 'comment()' function.  If we are
not in the process of parsing a 'Module' then the 'module' field will
be 'null' and the comment will be added to the 'List<DefinitionItem>'
that is stored in the 'items' field.  On the other hand, if we are in
the process of parsing a 'Module' then the 'module' field will not be
'null' and the comment will be added to the current 'module'.  Note
that the 'Module' production has to be careful to set the 'module'
field correctly.

*/


/***** LEXING COMPLICATIONS *****

*** LEXING STATES ***

The lexer rules for a K file differ in different parts of the file so
we have to switch between lexer states.

States:
 - Primary States: (these switch on specific tokens)
   - DEFAULT
   - BUBBLE_STATE: rhs of "rule" (SPECIAL_TOKEN includes whitespace)
   - KLABEL_STATE: rhs of priority or associativity declarations

 - Secondary States: (switch based on grammar context)
   - ATTR_STATE: used in body of Attributes (SPECIAL_TOKEN include whitespace)
   - TAG_STATE: used in body of Tags
   - REGEX_STATE: used in body of RegEx (SPECIAL_TOKEN includes whitespace)
   - GROUP_STATE: used in body of Group (i.e., a character class)

 - Tertiary States: (switch for one token)
   - MODNAME_STATE: used after "module", "interface" or "imports"

To avoid clutter we make separate token declarations for only those
tokens that are used in multiple places (in the DEFAULT state).

*** IDENTIFIER FORMS ***

UPPER_ID ::= "#"?["A"-"Z"]["a"-"z", "A"-"Z", "0"-"9"]*
LOWER_ID ::= "#"?["a"-"z"]["a"-"z", "A"-"Z", "0"-"9"]*

UPPER_ID (used in List{_})
UPPER_ID | LOWER_ID (used in FUN(...))

SortID ::= UPPER_ID ("{" UPPERID "}")?
  -- but no '#' allowed at front?

MOD_NAME ::= "#"?{[a-z0-9A-Z_]+ "-"}+

KLABEL ::= anything (other than "<")

ID (RegEx): [a-zA-Z][a-zA-Z0-9]*

KEY(Attribute): [a-z1-9][a-zA-Z0-9-]*

"List" is both "UPPER_ID" and custom operator

RL ::= ~[\[\]\_\ \n\r\t]+

*/

options {
  STATIC = false;
  UNICODE_INPUT = true;
  SUPPORT_CLASS_VISIBILITY_PUBLIC = false;
  TOKEN_MANAGER_USES_PARSER = true;
  // FORCE_LA_CHECK = true; // Useful for development, but causes a warning in Production()
}

PARSER_BEGIN(Outer)
package org.kframework.parser.outer;

import org.kframework.kil.ASTNode;
import org.kframework.kil.Attribute;
import org.kframework.kil.Attributes;
import org.kframework.kil.DefinitionItem;
import org.kframework.kil.Import;
import org.kframework.kil.KLabelConstant;
import org.kframework.kil.Lexical;
import org.kframework.kil.LiterateComment.LiterateCommentType;
import org.kframework.kil.LiterateDefinitionComment;
import org.kframework.kil.LiterateModuleComment;
import org.kframework.attributes.Location;
import org.kframework.kil.Module;
import org.kframework.kil.ModuleItem;
import org.kframework.kil.PriorityBlock;
import org.kframework.kil.PriorityBlockExtended;
import org.kframework.kil.PriorityExtended;
import org.kframework.kil.PriorityExtendedAssoc;
import org.kframework.kil.Production;
import org.kframework.kil.ProductionItem;
import org.kframework.kil.Require;
import org.kframework.kil.Restrictions;
import org.kframework.kil.NonTerminal;
import org.kframework.kil.Sort;
import org.kframework.attributes.Source;
import org.kframework.kil.StringSentence;
import org.kframework.kil.Syntax;
import org.kframework.kil.Terminal;
import org.kframework.kil.UserList;
import org.kframework.kil.loader.Context;

import org.kframework.utils.StringUtil;
import org.kframework.utils.errorsystem.KException.ExceptionType;
import org.kframework.utils.errorsystem.KException.KExceptionGroup;
import org.kframework.utils.errorsystem.KException;
import org.kframework.utils.errorsystem.KEMException;

import java.io.IOException;
import java.io.StringReader;
import java.util.ArrayList;
import java.util.Collections;
import java.util.Comparator;
import java.util.List;
import java.util.function.Function;
import java.util.regex.Matcher;
import java.util.regex.Pattern;
import java.util.stream.Collectors;
import java.util.stream.Stream;

// Comments get processed in an odd order that may cause them to be
// out of order.  Thus we sort module items by their *end* position so
// that comments within a module item are put before the module item
// but commends between module items are put between the module items.
class EndPositionComparator implements Comparator<ModuleItem> {
  public int compare(ModuleItem o1, ModuleItem o2) {
    int endLine1 = o1.getLocation().endLine(), endCol1 = o1.getLocation().endColumn();
    int endLine2 = o2.getLocation().endLine(), endCol2 = o2.getLocation().endColumn();
    if (endLine1 < endLine2 || endLine1 == endLine2 && endCol1 < endCol2) return -1;
    if (endLine1 > endLine2 || endLine1 == endLine2 && endCol1 > endCol2) return 1;
    return 0;
  }
}

public class Outer {
  private Source source;
  private List<DefinitionItem> items = new ArrayList<DefinitionItem>();;
  private Module module = null;
  private int beginLine, beginColumn;
  private Context context;

  /** Parses a given string that was read from 'source'. */
  public static List<DefinitionItem> parse(
    Source source, String string, Context context) {
    Outer parser = new Outer(new StringReader(string));
    parser.source = source;
    parser.context = context;
    try {
      return parser.Start();
    } catch (ParseException e) {
      throw KEMException.outerParserError("Encountered " + e.tokenImage[e.currentToken.next.kind]
            + ".\nWas expecting one of: " + Stream.of(e.expectedTokenSequences)
            // using an anonymous class because JavaCC doesn't support Java 8 syntax.
              .map(new Function<int[], String>() {
                public String apply(int[] is) {
                  StringBuilder sb = new StringBuilder();
                  for (int i : is) {
                    sb.append(e.tokenImage[i]);
                    sb.append(" ");
                  }
                  sb.deleteCharAt(sb.length() - 1);
                  return sb.toString();
                }
              }).collect(Collectors.toList()).toString(), e, source,
            new Location(e.currentToken.next.beginLine, e.currentToken.next.beginColumn, e.currentToken.next.endLine, e.currentToken.next.endColumn));
    } catch (TokenMgrError e) {
      // TODO: report location
      throw KEMException.outerParserError(e.getMessage(), e, source, null);
    }
  }

  /** Parses a given string that was read from 'source' as a list of
  attributes.  Note that the source position in the returned result is
  relative to the String. */
  public static Attributes parseAttributes(String string, Source source) throws ParseException {
    Outer parser = new Outer(new StringReader(string));
    parser.source = source;
    parser.module = null;
    parser.items = new ArrayList<DefinitionItem>();
    StringSentence ss = new StringSentence("", 0, 0, "", "");
    try {
      parser.AttributesBodyEOF(ss);
    } catch (TokenMgrError e) {
      throw new ParseException(e.getMessage());
    }
    return ss.getAttributes();
  }

  /***** Source Location *****/
  /** Returns the start location of the next token */
  private Location startLoc() {
    Token t = getToken(1);
    return new Location(beginLine + t.beginLine,
                        beginColumn + t.beginColumn, 0, 0);
  }

  /** Marks 'node' with the start position in 'locPrefix' and the end
  position of the last token.  Returns 'node' (which simplifies many
  uses of this function).
  */
  private <T extends ASTNode> T markLoc(Location locPrefix, T node) {
    return markLocExplicit(Location.apply(locPrefix.startLine(), locPrefix.startColumn(), token.endLine, token.endColumn), node);
  }

  /** Marks 'node' with the location in 'loc'.Returns 'node' (which
  simplifies many uses of this function).
  */
  private <T extends ASTNode> T markLocExplicit(Location loc, T node) {
    node.setSource(source);
    node.setLocation(loc);
    return node;
  }

  /** Marks 'node' with the start and end location of the last token.
  Returns 'node' (which simplifies many uses of this function).
  */
  private <T extends ASTNode> T tokenLoc(T node) {
    return markLoc(new Location(beginLine + token.beginLine, 
                                beginColumn + token.beginColumn, 0, 0), node);
  }

  /***** Token Processing *****/

  /** Returns the string of the last token. */
  private String image() {
    return token.image;
  }

  /** Returns the concatenation of the immediately preceding special tokens. */
  private String special() {
    StringBuilder sb = new StringBuilder();
    Token t = token;

    while ((t = t.specialToken) != null) {
      sb.insert(0, t.image);
    }

    return sb.toString();
  }

  /** Returns the concatenation of the immediately preceding special
  tokens and regular token. */
  private String specialAndImage() { return special() + image(); }

  /***** Misc Operations *****/

  /** Switches the lexer to a new state */
  private void SwitchTo(int state) {
    token_source.SwitchTo(state);
  }

  /** Adds a comment to the current module or definition list */
  void comment(Token token) {
    String str = token.image;
    if (str.startsWith("//"))
      str = str.substring(2, str.length() - 1); // remove // and \n from beginning and end
    else
      str = str.substring(2, str.length() - 2); // remove /* and */ from beginning and end

    LiterateCommentType lcType = LiterateCommentType.COMMON;

    if (str.startsWith("@")) {
      lcType = LiterateCommentType.LATEX;
      str = str.substring(1);
    } else if (str.startsWith("!")) {
      lcType = LiterateCommentType.PREAMBLE;
      str = str.substring(1);
    }

    Location loc = new Location(token.beginLine, token.beginColumn,
                                token.endLine, token.endColumn);
    if (module == null) {
      items.add(markLocExplicit(loc, new LiterateDefinitionComment(str, lcType)));
    } else {
      module.appendModuleItem(markLocExplicit(loc, new LiterateModuleComment(str, lcType)));
    }
  }

  static final private Pattern pattern = Pattern.compile(
    "(?s)\\s*\\[\\s*([^\\[\\]\\_\\ \\n\\r\\t]+)\\s*\\]\\s*:\\s*(.*)");

  /** Does the extra parsing needed to create a StringSentence */
  private StringSentence makeStringSentence(String type, String str,
      int sentenceBeginLine, int sentenceBeginColumn) {
    // First, try to parse any rule label at the start
    Matcher matcher = pattern.matcher(str);
    String content, label;
    int offset = 0;
    if (matcher.matches()) {
      content = matcher.group(2);
      label = matcher.group(1);
      offset = matcher.start(2);
    } else {
      content = str;
      label = "";
      offset = 0;
    }

    int startLine   = offsetLine(str, sentenceBeginLine, sentenceBeginColumn, offset);
    int startColumn = offsetColumn(str, sentenceBeginLine, sentenceBeginColumn, offset);
    // Second, try to parse any attributes at the end.
    // Unfortunately, attributes after a StringSentence are not
    // parsable by an LR parser so we have to try parsing at spots
    // where we think the attributes might start.
    for (int i = content.lastIndexOf('[');
         i >= 0;
         i = content.lastIndexOf('[', i - 1)) {
      Outer parser = new Outer(new StringReader(content.substring(i)));
      parser.source = this.source;
      parser.module = this.module;
      parser.items = this.items;
      parser.beginLine = offsetLine(str, sentenceBeginLine, sentenceBeginColumn, offset + i);
      parser.beginColumn = offsetLine(str, sentenceBeginLine, sentenceBeginColumn, offset + i);
      try {
        StringSentence ss = new StringSentence(content.substring(0, i), startLine, startColumn, type, label);
        parser.AttributesEOF(ss);
        return ss;
      } catch (ParseException e) {
        /* Our guess was wrong. Try another position. */
      } catch (TokenMgrError e) {
        /* Our guess was wrong. Try another position. */
      }
    }
    return new StringSentence(content, startLine, startColumn, type, label);
  }

  private int offsetLine(String str, int line, int column, int index)
  {
    if (index == 0) return line;
    SimpleCharStream s = new SimpleCharStream(new StringReader(str), line, column);
    try {
      for (int i = 0; i <= index; i++) { s.readChar(); }
    } catch (IOException e) { throw new AssertionError("did not expect IOException", e); }
    return s.getEndLine();
  }

  private int offsetColumn(String str, int line, int column, int index)
  {
    if (index == 0) return column;
    SimpleCharStream s = new SimpleCharStream(new StringReader(str), line, column);
    try {
      for (int i = 0; i <= index; i++) { s.readChar(); }
    } catch (IOException e) { throw new AssertionError("did not expect IOException", e); }
    return s.getEndColumn();
  }

}
PARSER_END(Outer)

/***** Default Token Rules *****/

<DEFAULT> SPECIAL_TOKEN :
{
  <COMMENT: ( "//" (~["\n", "\r"])* ("\n" | "\r")
            | "/*" (~["*"] | ("*")+ ~["/","*"])* ("*")+ "/")> { parser.comment(matchedToken); }
}

<DEFAULT> SKIP : { " " | "\t" | "\r" | "\n" }

<DEFAULT> TOKEN : 
{
  <RULE: "rule"> : BUBBLE_STATE
| <CONTEXT: "context"> : BUBBLE_STATE
| <CONFIGURATION: "configuration"> : BUBBLE_STATE

| <SYNTAX: "syntax">
| <ENDMODULE: "endmodule">
| <ENDINTERFACE: "endinterface">

| <PRIORITY: "priority"> : KLABEL_STATE
| <PRIORITIES: "priorities"> : KLABEL_STATE
| <NON_ASSOC: "non-assoc"> // : KLABEL_STATE

| <MODULE: "module"> : MODNAME_STATE
| <INTERFACE: "interface"> : MODNAME_STATE
| <IMPORTS: "imports"> : MODNAME_STATE
| <IMPORTS2: "import"> : MODNAME_STATE

| <STRING: "\"" (~["\"", "\\", "\n"] |
                 "\\\"" | "\\n" | "\\r" | "\\t" | "\\\\")* "\"">
| <STRING_CASE_INSENSITIVE: "\'" (~["\'", "\\", "\n"] |
                 "\\\'" | "\\n" | "\\r" | "\\t" | "\\\\")* "\'">
| <STRING_REGEX: "r\"" (~["\"", "\\", "\n"] |
                 "\\\"" | "\\n" | "\\r" | "\\t" | "\\\\")* "\"">

| <LPAREN: "(">
| <RPAREN: ")">
| <LCURLY: "{">
| <RCURLY: "}">
| <LSQUARE: "[">
| <RSQUARE: "]">

| <GT: ">">
| <PLUS: "+">
| <TIMES: "*">
| <QUESTION: "?">
| <TILDE: "~">
| <COMMA: ",">

| <LEFT: "left">
| <RIGHT: "right">

| "List"
| "NeList"
| "Lexer"
| "Token"

| "require"
| "requires"

| <UPPER_ID: ("#")?["A"-"Z"](["a"-"z", "A"-"Z", "0"-"9"])*>
| <LOWER_ID: ("#")?["a"-"z"](["a"-"z", "A"-"Z", "0"-"9"])*>
}

/** Parses an UPPER_ID token, but also allows List, NeList, Lexer, and
Token unlike the default UPPER_ID.
*/
void UpperId() : {}
{
  <UPPER_ID> | "List" | "NeList" | "Lexer" | "Token"
}

/** Parses a string literal and returns the decoded value of that string. */
String String() : {}
{
  <STRING>
  {
    String s = image();
    return StringUtil.unquoteCString(s);
  }
}
String StringCaseInsensitive() : {}
{
  <STRING_CASE_INSENSITIVE>
  {
    String s = image();
    return StringUtil.unquoteCString(s, '\'');
  }
}
String StringRegex() : {}
{
  <STRING_REGEX>
  {
    String s = image();
    return StringUtil.unquoteCString(s.substring(1), '\"');
  }
}

/** Parses and returns a NonTerminal but not a List, NeList, Lexer, or Token */
NonTerminal SimpleSortID() : { Location loc = startLoc(); String str; }
{
  <UPPER_ID> { str = image(); }
  ("{"  { str = str + specialAndImage(); }
   UpperId() { str = str + specialAndImage(); }
   "}"  { str = str + specialAndImage(); })?
  { return markLoc(loc, new NonTerminal(Sort.of(str))); }
}

/** Parses and returns a NonTerminal */
NonTerminal SortID() : { NonTerminal nonTerminal; }
{
  nonTerminal = SimpleSortID() { return nonTerminal; }
  | ("List" | "NeList" | "Lexer" | "Token")
    { return tokenLoc(new NonTerminal(Sort.of(image()))); }
}

///////

<MODNAME_STATE> SPECIAL_TOKEN: {
  <MODNAME_COMMENT: <COMMENT>> { parser.comment(matchedToken); } }
<MODNAME_STATE> SKIP: { " " | "\t" | "\r" | "\n" }
<MODNAME_STATE> TOKEN:
{
  <MODNAME: ("#")?(["a"-"z", "0"-"9", "A"-"Z", "_"])+
             ("-" (["a"-"z", "0"-"9", "A"-"Z", "_"])+)*> : DEFAULT
}

/**** String Sentence Bubbles ****/

<BUBBLE_STATE> SPECIAL_TOKEN:
{
  <([" ", "\t", "\r", "\n"])+>
| <BUBBLE_COMMENT: <COMMENT>> { parser.comment(matchedToken); }
}

<BUBBLE_STATE> TOKEN:
{
  "syntax"        { matchedToken.kind = SYNTAX; } : DEFAULT
| "endmodule"     { matchedToken.kind = ENDMODULE; } : DEFAULT
| "endinterface"  { matchedToken.kind = ENDINTERFACE; } : DEFAULT

| "rule"          { matchedToken.kind = RULE;    } : BUBBLE_STATE
| "configuration" { matchedToken.kind = CONFIGURATION;  } : BUBBLE_STATE
| "context"       { matchedToken.kind = CONTEXT; } : BUBBLE_STATE

// Note that "BUBBLE" must be last so it doesn't match keywords
| <BUBBLE: (~[" ", "\t", "\r", "\n"])+>
}

/** Parses and returns an unparsed bubble */
StringSentence Bubble(String type) :
{
  StringBuilder sb = new StringBuilder();
  int sentenceBeginLine = beginLine + token.endLine;
  int sentenceBeginColumn = beginColumn + token.endColumn + 1;
}
{
  (<BUBBLE> { sb.append(image());
              sentenceBeginLine = beginLine + token.beginLine;
              sentenceBeginColumn = beginColumn + token.beginColumn; }
   (<BUBBLE> { sb.append(specialAndImage()); })*)?
  { return makeStringSentence(type, sb.toString(),
      sentenceBeginLine, sentenceBeginColumn); }
}

/**** KLabels ****/

<KLABEL_STATE> SPECIAL_TOKEN: {
  <KLABEL_COMMENT: <COMMENT>> { parser.comment(matchedToken); } }
<KLABEL_STATE> SKIP: { " " | "\t" | "\r" | "\n" }

<KLABEL_STATE> TOKEN:
{
  "syntax"        { matchedToken.kind = SYNTAX; } : DEFAULT
| "endmodule"     { matchedToken.kind = ENDMODULE; } : DEFAULT
| "endinterface"  { matchedToken.kind = ENDINTERFACE; } : DEFAULT

| "rule"          { matchedToken.kind = RULE;    } : BUBBLE_STATE
| "configuration" { matchedToken.kind = CONFIGURATION;  } : BUBBLE_STATE
| "context"       { matchedToken.kind = CONTEXT; } : BUBBLE_STATE

| ">"             { matchedToken.kind = GT; }
| <KLABEL: (~[" ", "\t", "\r", "\n"])+> // Must be last
}

/** Parses a list of KLabels and returns them */
List<KLabelConstant> KLabels() :
{ List<KLabelConstant> list = new ArrayList<KLabelConstant>(); }
{
  // Note that we don't assign location information b/c KLabels are interned
  (<KLABEL> { list.add(KLabelConstant.of(image())); })+
  // TODO: check if need context
  { return list; }
}

/**** RegEx ****/

<REGEX_STATE> SPECIAL_TOKEN: {
  <([" ", "\t", "\r", "\n"])+>
| <REGEX_COMMENT: <COMMENT>> { parser.comment(matchedToken); }
}

<REGEX_STATE> TOKEN:
{
  <ID: ["A"-"Z"](["a"-"z", "A"-"Z", "0"-"9"])*>
| <REGEX_STRING: <STRING>> { matchedToken.kind = STRING; }
| "(" { matchedToken.kind = LPAREN; }
| ")" { matchedToken.kind = RPAREN; }
| "{" { matchedToken.kind = LCURLY; }
| "}" { matchedToken.kind = RCURLY; }
| "[" { matchedToken.kind = LSQUARE; }
| "]" { matchedToken.kind = RSQUARE; }
| "+" { matchedToken.kind = PLUS; }
| "*" { matchedToken.kind = TIMES; }
| "?" { matchedToken.kind = QUESTION; }
| "~" { matchedToken.kind = TILDE; }
| <PIPE: "|">
}

/** Parses a complete RegEx and returns it as a String */
String RegEx(StringBuilder follow): { StringBuilder reg = new StringBuilder(); }
{ (Element(reg, follow))+ {
    String regEx = reg.toString();
    if (!regEx.endsWith("*") && !regEx.endsWith("+") && !regEx.endsWith("?"))
        follow.setLength(0);
    return reg.toString(); } }

/** Parses a single RegEx Element and appends it to 'sb' */
void Element(StringBuilder reg, StringBuilder follow) :
{ StringBuilder sb = new StringBuilder(); }
{
  { follow.setLength(0); }
  BasicElement(sb, follow)
  (<PIPE> { sb.append(specialAndImage()); } BasicElement(sb, follow) { follow.setLength(0); })*
  { reg.append(sb); }
}

/** Parses a single RegEx BasicElement and appends it to 'sb' */
void BasicElement(StringBuilder sb, StringBuilder follow) : {}
{
( <STRING>  { sb.append(specialAndImage()); follow.setLength(0); }
| <ID>      { sb.append(StringUtil.escapeSort(specialAndImage())+"Dz"); follow.setLength(0); }
| Group(sb, REGEX_STATE) { follow.append(sb); }
| "{"       { sb.append(specialAndImage()); }
  Element(sb, follow)
  <STRING>  { sb.append(specialAndImage()); }
  "}" { sb.append(specialAndImage()); }
  (("+" | "*") { sb.append(specialAndImage()); follow.setLength(0); })
| "("       { sb.append(specialAndImage()); }
  (Element(sb, follow))*
  ")"       { sb.append(specialAndImage()); follow.setLength(0); }
) (("+" | "*" | "?" ) { sb.append(specialAndImage()); })*
}

/*** RegEx Character Groups */

<GROUP_STATE> TOKEN:
{ <GROUP: ( ["a"-"z", "A"-"Z", "0"-"9"]
          | "-" | "\t" | "\n" | "\r" | " "
          | "\\" ["t", "n", "r", " "]
          | "\\" ~["a"-"z", "A"-"Z", "\t"])*>
    { if (image.length() > 0)
      if (image.charAt(0) == '-' ||
    		(image.charAt(image.length() - 1) == '-'
    		 && image.charAt(image.length() - 2) != '\\')) {
        throw new TokenMgrError(
          "Lexical error at line " + matchedToken.beginLine +
          ", column " + matchedToken.beginColumn + ". Found \"-\" at " +
          (image.charAt(0) == '-' ? "start" : "end") +
          " of character group in regular expression.",
          TokenMgrError.LEXICAL_ERROR);
      }
    }
}

/** Parses a single character group and appends it to 'sb' */
void Group(StringBuilder sb, int state) : {}
{
  "~"      { sb.append(specialAndImage()); } Group(sb, state)
| "["      { sb.append(specialAndImage()); SwitchTo(GROUP_STATE); }
  (<GROUP> { sb.append(specialAndImage()); })? { SwitchTo(state); }
  "]"      { sb.append(specialAndImage()); }
}

/*** Attributes ***/

<ATTR_STATE> SPECIAL_TOKEN:
{
  "\n" | "\r" | " " | "\t"
| <ATTR_COMMENT: <COMMENT>> { parser.comment(matchedToken); }
}

<ATTR_STATE> TOKEN:
{
  "," { matchedToken.kind = COMMA; }
| "[" { matchedToken.kind = LSQUARE; }
| "]" { matchedToken.kind = RSQUARE; }
| "(" { matchedToken.kind = LPAREN; }
| ")" { matchedToken.kind = RPAREN; }
| <KEY: ["a"-"z","1"-"9"](["A"-"Z", "a"-"z", "-", "0"-"9"])*("<" (["A"-"Z", "a"-"z", "-", "0"-"9"])+ ">")?>
}

/** The same as 'Attributes()', but requires that the entire input be
consumed.  Used for implementing the re-parsing in
makeStringSentence.
*/
void AttributesEOF(ASTNode node) : {} { Attributes(node) <EOF> }
void AttributesBodyEOF(ASTNode node) : {} {
  { SwitchTo(ATTR_STATE); } AttributesBody(node) <EOF> { SwitchTo(DEFAULT); } }

/** Parses a set of attributes and adds them to 'node' */
void AttributesBody(ASTNode node) : {} { Tag(node) ("," Tag(node))* }
void Attributes(ASTNode node) : {}
{
  "[" { SwitchTo(ATTR_STATE); }
  AttributesBody(node)
  "]" { SwitchTo(DEFAULT); }
}

<TAG_STATE> TOKEN:
{
  "(" { matchedToken.kind = LPAREN; }
| ")" { matchedToken.kind = RPAREN; }
| <TAG_STRING: <STRING>> { matchedToken.kind = STRING; }
| <TAG_CONTENT: (~["\n", "\r", "(", ")", "\""])+>
}

/** Parses a single attribute and adds it to 'node' */
void Tag(ASTNode node) :
{ Location loc = startLoc(); String key; String val = "";
  StringBuilder sb = new StringBuilder(); }
{
  <KEY> { key = image(); }
  ( "(" { SwitchTo(TAG_STATE); }
    ( val = String() ")"
    | TagContent(sb) ")" { val = sb.toString() + special(); } )
    { SwitchTo(ATTR_STATE); })?
  { node.addAttribute(markLoc(loc, Attribute.of(key, val))); }
}

/** Parses the value of an attribute and appends it to 'sb' */
void TagContent(StringBuilder sb) : {}
{
( <TAG_CONTENT> { sb.append(specialAndImage()); }
| "(" { sb.append(specialAndImage()); }
  TagContent(sb)
  ")" { sb.append(specialAndImage()); }
)*
}

/***** MAIN GRAMMAR *****/

/** Parses a file and returns a List of its contents */
List<DefinitionItem> Start() : {}
{
  (Require(items))* (Module(items))* <EOF>
  { return items; }
}

/** Parses a Require clause and adds it to items */
void Require(List<DefinitionItem> items) :
{ Location loc = startLoc(); String str; }
{
  ("require" | "requires") str = String() { items.add(markLoc(loc, new Require(str))); }
}

/** Parses a Module and adds it to items */
void Module(List<DefinitionItem> items) : { Location loc = startLoc(); }
{
  "module" <MODNAME> { module = new Module(image()); }
    (Import(module))*
    (Sentence(module))*
  "endmodule" {
    // Sort to put comments in order
    Collections.sort(module.getItems(), new EndPositionComparator());
    items.add(markLoc(loc, module));
    module = null; }
}

/** Parses an Import and adds it to module */
void Import(Module module): { Location loc = startLoc(); }
{
  ("imports" | "import") <MODNAME>
  { module.appendModuleItem(markLoc(loc, new Import(image()))); }
}

/** Parses a Sentence and adds it to 'module' */
void Sentence(Module module) :
{ Location loc = startLoc();
  String type, str;
  StringBuilder sb = new StringBuilder();
  NonTerminal nonTerminal;
  StringSentence ss;
  List<KLabelConstant> list; }
{
  ("rule" | "context" | "configuration")
  { type = image();
    // Note that we must change the "type"
    if (type.equals("configuration")) { type = "config"; } }
  ss = Bubble(type) { module.appendModuleItem(markLoc(loc, ss)); }

| "syntax"
  ( nonTerminal = SortID() { Syntax syn = new Syntax(nonTerminal); }
    ( "::=" { List<PriorityBlock> pblocks = new ArrayList<PriorityBlock>(); }
      PriorityBlock(pblocks) (">" PriorityBlock(pblocks))*
      { syn.setPriorityBlocks(pblocks); }
    | Attributes(syn)
    | "-/-" Group(sb, DEFAULT) ("." { sb.append(specialAndImage()); } Group(sb, DEFAULT))*
      { module.appendModuleItem(markLoc(loc, new Restrictions(
          new NonTerminal(syn.getDeclaredSort().getRealSort()), null, sb.toString()))); return; } )?
    { module.appendModuleItem(markLoc(loc, syn)); }
  
  | ("priority" | "priorities")
      { List<PriorityBlockExtended> pblocks =
          new ArrayList<PriorityBlockExtended>(); }
      list = KLabels() { pblocks.add(new PriorityBlockExtended(list)); }
      (">" list = KLabels() { pblocks.add(new PriorityBlockExtended(list)); })*
    { module.appendModuleItem(markLoc(loc, new PriorityExtended(pblocks))); }
  | ("left" | "right" | "non-assoc") { SwitchTo(KLABEL_STATE); type = image(); }
      list = KLabels()
    { module.appendModuleItem(markLoc(loc, new PriorityExtendedAssoc(type, list))); }
  
  | type = String() "-/-"
      Group(sb, DEFAULT) ("." { sb.append(specialAndImage()); } Group(sb, DEFAULT))*
      { module.appendModuleItem(markLoc(loc, new Restrictions(
          null, new Terminal(type), sb.toString()))); }
  )
}


/***** Syntax Productions *****/

/** Parses a PriorityBlock and adds it to 'pblocks' */
void PriorityBlock(List<PriorityBlock> pblocks) :
{ Location loc = startLoc(); String assoc = "";
  List<Production> prods = new ArrayList<Production>(); }
{
  (("left" | "right" | "non-assoc") { assoc = image(); } ":")?
  Production(prods) ("|" Production(prods))*
  { pblocks.add(markLoc(loc, new PriorityBlock(assoc, prods))); }
}

/** Parses a Production and adds it to 'prods' */
void Production(List<Production> prods) :
{ Location loc = startLoc(); NonTerminal nonTerminal;
  List<ProductionItem> items = new ArrayList<ProductionItem>();
  String klabel = null; }
{
( LOOKAHEAD((UpperId() | <LOWER_ID>) "(")
  (UpperId() | <LOWER_ID>)
  { items.add(tokenLoc(new Terminal(image()))); klabel = image(); }
  "("              { items.add(tokenLoc(new Terminal(image()))); }
  nonTerminal = SortID()  { items.add(nonTerminal); }
  (","             { items.add(tokenLoc(new Terminal(image()))); }
   nonTerminal = SortID() { items.add(nonTerminal); }
  )*
  ")"              { items.add(tokenLoc(new Terminal(image()))); }
| "("              { items.add(tokenLoc(new Terminal(image()))); }
  nonTerminal = SortID()  { items.add(nonTerminal); }
  (","             { items.add(tokenLoc(new Terminal(image()))); }
   nonTerminal = SortID() { items.add(nonTerminal); }
  )*
  ")"              { items.add(tokenLoc(new Terminal(image()))); }
| (ProductionItem(items))+
) { Production prod = new Production(new NonTerminal(Sort.of("")), items); }
  (Attributes(prod))?
  { if (klabel != null && prod.getAttribute("klabel") == null) {
      prod.addAttribute("klabel", "'"+klabel);
    }
    prods.add(markLoc(loc, prod)); }
}

/** Parses a ProductionItem and adds it to 'items' */
void ProductionItem(List<ProductionItem> items) :
{ Location loc = startLoc(); String str; String sep; NonTerminal nonTerminal;
  StringBuilder follow = new StringBuilder(); boolean isToken = false; }
{
  str = String()                { items.add(tokenLoc(new Terminal(str))); }
| str = StringCaseInsensitive() { items.add(tokenLoc(new Terminal(str, true))); }
| str = StringRegex()           { items.add(tokenLoc(new Lexical(str, ""))); }
| nonTerminal = SimpleSortID()  { items.add(nonTerminal); }
| "List"
  ( "{" UpperId() { str = image(); } "," sep = String() "}"
    { items.add(markLoc(loc, new UserList(Sort.of(str), sep, "*"))); return; })?
  { items.add(tokenLoc(new NonTerminal(Sort.of(image())))); }
| "NeList"
  ( "{" UpperId() { str = image(); } "," sep = String() "}"
    { items.add(markLoc(loc, new UserList(Sort.of(str), sep, "+"))); return; })?
  { items.add(tokenLoc(new NonTerminal(Sort.of(image())))); }
| ("Lexer" | "Token" { isToken = true; })
  ( "{" { SwitchTo(REGEX_STATE); }
    str = RegEx(follow)
    "}" { SwitchTo(DEFAULT);
          items.add(markLoc(loc, new Lexical(
            str+special(),
            isToken && follow.length() != 0 ?
               follow.toString() : null)));
          return; })?
  { items.add(tokenLoc(new NonTerminal(Sort.of(image())))); }
}
